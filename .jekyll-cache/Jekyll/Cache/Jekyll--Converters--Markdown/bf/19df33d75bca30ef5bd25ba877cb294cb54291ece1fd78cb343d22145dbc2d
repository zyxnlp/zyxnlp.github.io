I"ÛZ<div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2021ToBC" class="col-sm-8">
    
      <div class="title">To be Closer: Learning to Link up Aspects with Opinions</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liao, Lejian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gao, Yang,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://allanj.github.io/">Jie, Zhanming</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lu, Wei
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of EMNLP</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://arxiv.org/abs/2109.08382" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Dependency parse trees are helpful for discovering the opinion words in aspect-based sentiment analysis (ABSA). However, the trees obtained from off-the-shelf dependency parsers are static, and could be sub-optimal in ABSA. This is because the syntactic trees are not designed for capturing the interactions between opinion words and aspect words. In this work, we aim to shorten the distance between aspects and corresponding opinion words by learning an aspect-centric tree structure. The aspect and opinion words are expected to be closer along such tree structure compared to the standard dependency parse tree. The learning process allows the tree structure to adaptively correlate the aspect and opinion words, enabling us to better identify the polarity in the ABSA task. We conduct experiments on five aspect-based sentiment datasets, and the proposed model significantly outperforms recent strong baselines. Furthermore, our thorough analysis demonstrates the average distance between aspect and opinion words are shortened by at least 19% on the standard SemEval Restaurant14 dataset.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2021TopicBERTAT" class="col-sm-8">
    
      <div class="title">TopicBERT: A Topic-Enhanced Neural Language Model Fine-Tuned for Sentiment Classification.</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liao, Lejian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gao, Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Rui,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Huang, Heyan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE transactions on neural networks and learning systems</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9508773" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sentiment classification is a form of data analytics where people‚Äôs feelings and attitudes toward a topic are mined from data. This tantalizing power to ‚Äúpredict the zeitgeist‚Äù means that sentiment classification has long attracted interest, but with mixed results. However, the recent development of the BERT framework and its pretrained neural language models is seeing new-found success for sentiment classification. BERT models are trained to capture word-level information via mask language modeling and sentence-level contexts via next sentence prediction tasks. Out of the box, they are adequate models for some natural language processing tasks. However, most models are further fine-tuned with domain-specific information to increase accuracy and usefulness. Motivated by the idea that a further fine-tuning step would improve the performance for downstream sentiment classification tasks, we developed TopicBERT‚Äìa BERT model fine-tuned to recognize topics at the corpus level in addition to the word and sentence levels. TopicBERT comprises two variants: TopicBERT-ATP (aspect topic prediction), which captures topic information via an auxiliary training task, and TopicBERT-TA, where topic representation is directly injected into a topic augmentation layer for sentiment classification. With TopicBERT-ATP, the topics are predetermined by an LDA mechanism and collapsed Gibbs sampling. With TopicBERT-TA, the topics can change dynamically during the training. Experimental results show that both approaches deliver the state-of-the-art performance in two different domains with SemEval 2014 Task 4. However, in a test of methods, direct augmentation outperforms further training. Comprehensive analyses in the form of ablation, parameter, and complexity studies accompany the results.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2021ExtractingSF" class="col-sm-8">
    
      <div class="title">Extracting salient features from convolutional discriminative filters</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liao, Lejian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gao, Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Huang, Heyan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Information Sciences</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S0020025521000165?via%3Dihub" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Convolutional neural networks (CNN) have been widely used in various tasks, largely dueto their ability to efficiently extract n-gram features for text analysis and document repre-sentation. In this paper, we intend to insight the CNN model regarding its capability on textanalysis. Vanilla CNNs do have weaknesses when it comes to the representation and fea-ture extraction. Duplicate filters are inevitable with vanilla CNNs, which reduces the dis-criminative power of the representations. In addition, the current pooling operationseither limit the CNN to the local optimum (i.e., max pooling) or they do not consider theimportance of all features (i.e., mean pooling). In this paper, we propose two modulesfor vanilla CNNs to overcome these shortcomings. The first equips the CNN with discrim-inative filters (distinct filters with maximised divergence) and the second provides theability to comprehensively extract all salient features. Specifically, our model increasesthe discriminative power of the model by maximizing the distance between different fil-ters, and a novel global pooling mechanism for feature extraction. Validation tests againststate-of-the-art baselines on five benchmark classification datasets achieve the competi-tive performance of our proposed model. Furthermore, visualization on upgrade filtersand pooling features verify our hypothesis that the proposed model can receive discrimi-native filters and salient features.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2020ADC" class="col-sm-8">
    
      <div class="title">A Discriminative Convolutional Neural Network with Context-aware Attention</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liao, Lejian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gao, Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Huang, Heyan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wei, Xiaochi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM Transactions on Intelligent Systems and Technology (TIST)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3397464" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Wenbo2019ConceptPN" class="col-sm-8">
    
      <div class="title">Concept Pointer Network for Abstractive Summarization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Wenbo, Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gao, Yang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Heyan, Huang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>Zhou, Yuxiang</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of EMNLP</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://aclanthology.org/D19-1304/" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distant-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC-2004 and Gigaword datasets. A human evaluation of the model‚Äôs abstractive abilities also supports the quality of the summaries produced within this framework.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Qiao2019ASW" class="col-sm-8">
    
      <div class="title">A simple water cycle algorithm with percolation operator for clustering analysis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Qiao, Shilei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Yongquan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wang, Rui
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Soft Computing</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://link.springer.com/article/10.1007%2Fs00500-018-3057-5" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2017ASM" class="col-sm-8">
    
      <div class="title">A simplex method-based social spider optimization algorithm for clustering analysis</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Zhou, Yongquan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Luo, Qifang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Abdel-Basset, Mohamed
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Engineering Applications of Artificial Intelligence (EAAI)</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197617301239?via%3Dihub" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2016ANC" class="col-sm-8">
    
      <div class="title">A Novel Complex-Valued Social Spider Optimization Algorithm</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Yongquan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Luo, Qifang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qiao, Shilei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wang, Rui
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Computational and Theoretical Nanoscience</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://www.ingentaconnect.com/content/asp/jctn/2016/00000013/00000005/art00080" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Zhou2015DriftOF" class="col-sm-8">
    
      <div class="title">Drift Operator for States of Matter Search Algorithm</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Zhou, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Yongquan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Luo, Qifang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qiao, Shilei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Wang, Rui
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Intelligent Computing (ICIC)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-22053-6_7" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--  <div class="col-sm-2 abbr">-->
<!--  -->
<!--  </div>-->

  <div id="Qiao2015SelfadaptivePB" class="col-sm-8">
    
      <div class="title">Self-adaptive Percolation Behavior Water Cycle Algorithm</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Qiao, Shilei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Yongquan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Rui,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>Zhou, Yuxiang</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Intelligent Computing (ICIC)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-22180-9_9" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>


</div>
:ET